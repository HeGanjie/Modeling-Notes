# task_04 回归分析3_线性回归模型的误差诊断

[教程地址](https://github.com/Git-Model/Modeling-Universe/blob/main/Data%20Analysis%20and%20Statistical%20Modeling/task_04%20%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%903_%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AF%AF%E5%B7%AE%E8%AF%8A%E6%96%AD/%E5%9B%9E%E5%BD%923.ipynb)

#### 简单总结
5. CLM假设误差分析
  * 主要目的是分析违反某条CLM假设具体会给模型估计带来多大的影响
  * 估计系数的方差构成与多重共线性
    * 自变量 x1 本身的总变异 SST1：根据公式，对于一个分析任务来说，样本量越大，总变异也就越大，进而估计方差会变小，这告诉我们更多的随机样本有利于提高估计的精度
    * 一般用方差膨胀因子(VIF,Variance Inflation Factor)来衡量共线性的严重程度，若大于 10，意味着共线性很严重，需要采取措施降低共线性
    * 总结降低估计方差，提高估计精度的方法：
      * 采取更合理的数据采样方法，降低数据噪声。
      * 增大数据样本量
      * 根据线性相关程度筛选纳入模型的变量，且切忌纳入过多变量
  * 模型误设的误差分析
    * 违反MLR.1的后果是什么
      * 根据公式，对于遗漏变量 xk ，除非 βk=0 （即 xk 对 y 完全不影响），或者 δ1=0 （遗漏变量 xk 与待分析自变量 x1 不相关），否则遗漏变量会对我们实际估计模型的系数估计产生有偏影响，即我们的系数估计不再是平均意义上的准确
      * 对于增加一个对解释因变量无益的自变量，一旦这个无益自变量与其它自变量存在共线性，则会增大其他估计系数的估计方差
    * 变量选择的方法论
      * 我们总结一下以上的内容：
        * 减少模型中的变量，可能会导致模型其他系数的估计有偏，但是会使系数估计的方差减少，即：增大偏差、减小方差
        * 增加模型中的变量，不会导致模型系数估计有偏，但是会使系数估计的方差增大，即：减小偏差、增大方差
      * 通常来说，有两种考量纳入变量的方法论：
        * 从少数变量开始，一步步向模型纳入我们认为重要的变量，并通过t检验显著性来判断是否纳入该变量；如果我们认为变量存在二次项效应与交互项效应，可以将其纳入模型并通过联合F检验判断其显著性，直到模型的解释度达到一个较高的水平（变量非常多）
        * 从多数变量开始，一步步将不显著的变量剔除出模型（变量不多）
    * 模型不满足正态性的分析——违反MLR.6的后果是什么
      * 先说结论：在样本量较大的情况下，不满足MLR.6不会有什么不好的后果
      * 如何理解与观测正态性假设
        * 由于在 x 已知的条件下， u 的正态性等价于 y 的正态性，因此我们只需要查看样本因变量 y 的分布图就可以大致判断正态性了
      * 违背正态性假设的后果
        * 违背正态性假设不会影响OLS系数估计的准确性与稳定性
    * 异方差的分析——违反MLR.5的后果是什么（简单来说就是 x 越大 y 越离散）
      * 首先由于MLR.1-MLR.4仍然成立，因此系数估计的无偏性依然成立。
      * 异方差下，OLS估计不再是最优线性无偏估计。
      * 异方差下，估计系数的方差计算不再准确，从而影响到标准误的计算，进而影响到t检验与F检验的有效性。
    * 异方差下的回归分析
      * 异方差稳健的t检验与F检验：具体差异看代码
      * 异方差的诊断
        * BP异方差检验：
          * 是检验异方差与所有自变量的一次项无关，这就等价于对一个以 $u^2$ 为因变量，以 $x_j$ 为自变量的线性回归模型（具体做法看代码）
          * 考虑的是是否存在与变量的一次项相关的异方差
        * White异方差检验
          * 公式跟 BP 检验一样，但增加了对所有变量二次项以及交互项的考察
      * 广义最小二乘法
        * 如果异方差可以用自变量的函数被表达出来，我们就可以是加权最小二乘估计WLS；如果由于函数形式复杂而无法被判断出来，我们则使用可行的广义最小二乘估计FGLS
        * WLS：用法见教程代码，如果存在异方差，则 WLS 返回结果系数标准误会更小
        * FGLS：估计出 h(x) 的形式，再使用wls估计法求解模型。这种方法又称为FGLS
  
#### 作业
[作业解答链接](https://colab.research.google.com/drive/1rCxxKzgndqOHz5Stvcdtuqt0w0NQC0Y5#scrollTo=RqUMiKql59P_)

#### 体会

1. 部分数学公式看不懂，果然我还是菜。只能退而求其次，先尝试在实际问题用起来，再深入探究其原理
2. 感觉如果教程写得更通俗一些会不会更好？例如不能拒绝原假设 -> 维持假设

